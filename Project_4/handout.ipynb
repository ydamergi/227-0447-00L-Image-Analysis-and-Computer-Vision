{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vAGgKQAtVCBjDj6vLxBF9p0TDHxCizGE","timestamp":1667135958660}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercise 4: Image Classification\n","\n","\n","Given an input RGB image, you should train a neural network which outputs the class label the image belongs to.\n","There are six class labels in our dataset: \"buildings\", \"forests\", \"mountains\", \"glacier\", \"sea\", and \"street\".\n","In order to design and train your network, we provide a training set and validation set along with class labels for every image.\n","As you are already familiar, we separate the dataset into three splits: training, validation, and testing.\n","The train set has 6K images (1K per class), and the val and test sets each have 1.2K images (200 per class).\n","\n","An overview of the desired pipeline is shown in Figure.\n","\n","\n","![](https://docs.google.com/drawings/d/e/2PACX-1vRynZcZ1jfCu1GAsY9Hww68kr3iGaHj5XKeQptkF9lRysFpMtbbs4TZZaklAemoZJbMR-LUQnVkkI0b/pub?w=680&h=483 \"Title\")\n","\n","\n","This exercise acts as a gentle introduction to [PyTorch](https://pytorch.org/), one of the most popular deep learning frameworks.\n","We provide a majority of the code to get you started and familiarized with the framework.\n","Running through all the cells will give you a simple linear network that can achieve the baseline performance.\n","To pass, you will need to modify the given implementation and train a network that can achieve better performance.\n","\n","**Evaluation Criteria**\n","\n","Your algorithm will be evaluated using classification accuracy, which is the proportion of images with the correct predicted label.\n","The final EvaluationScore is obtained as the classification accuracy over all test samples.\n","\n","**Passing requirement**\n","\n","Your algorithm will be evaluated on a test set. In order to pass the exercise, you need to obtain an EvaluationScore of **greater than $70.0$** on the test set."],"metadata":{"id":"dnLsCjLDMiCO"}},{"cell_type":"markdown","source":["## Initialize the environment and load data\n","Import the necessary libraries. Note that you are **NOT** allowed to use any additional libraries"],"metadata":{"id":"BTx8Wss3eD0j"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9eaRYAf_iWs"},"outputs":[],"source":["# These two lines ensure that we always import the latest version of a package, in case it has been modified.\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","import sys\n","import shutil\n","from pathlib import Path\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**TODO:** Set the path in Google drive where you uploaded the handout, e.g. My Drive/iacv/ex4\n","\n"],"metadata":{"id":"L_TTjEHrMfIK"}},{"cell_type":"code","source":["iacv_path = '...' # TODO set this\n","\n","# Add the handout folder to python paths\n","env_path = Path('/content/drive') / iacv_path\n","data_path = env_path / 'data'\n","if env_path not in sys.path:\n","    sys.path.append(str(env_path))\n","\n","from utils import show_images"],"metadata":{"id":"GTVU1pMT_pMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Overview\n","\n","In general, training any deep learning models consists of the following components\n","\n","\n","*   **Dataset:** The data on which the model is trained. This could be e.g. large number of images, videos, text documents etc.\n","*   **Model:** The network architecture we want to train. A significant part of developing deep learning solutions involves designing right architecture for a given problem.\n","*   **Cost Function:** The criteria which is minimized over our dataset to train the network, e.g. Cross-entropy loss, Mean-squared error.  \n","*   **Optimizer:** The optimizer updates the model parameters to minimize the cost function. The most common example is Stochastic Gradient Descent. One also has to determine hyperparameters such as the learning rate, number of optimization iterations etc.\n","\n","As discussed in the lectures, the deep networks are trained using *mini-batches*, which are a set of training images (commonly between 8-128). Furthermore, data augmentation strategies (e.g. rotating an image) are commonly used to 'transform' the training images first, before passing it to a network. Thus, the data loading step itself can be broken down into following sub-steps,\n","1.   Load an image from the dataset. The images are randomly loaded from the dataset during training to avoid any bias.\n","2.   Apply necessary pre-processing to the image, e.g. remove mean, convert datatype to `float` etc.\n","3.   Apply desired data augmentations to the image, e.g. rotate an image, extract a random crop from the image.\n","4. Group a number of processed images to form a 'training batch'. This batch is then passed through the network to obtain predictions and compute loss.\n","\n","\n","\n","\n","We will use the [PyTorch](https://pytorch.org/) deep learning framework to implement each of these components. Follow through the next cells to check the implementation.\n"],"metadata":{"id":"-FhZEDX4gheL"}},{"cell_type":"markdown","source":["## Step 1: Data Loading\n","\n","We first take a look at how to define the datasets and data loading procedures in PyTorch.\n","\n","To do so, we need to create a PyTorch Dataset and DataLoader.\n","The PyTorch Dataset handles loading the actual images and labels from file as well as applying any transformations on the loaded image. To define your own Dataset, you need to subclass the `torch.utils.data.Dataset` class and implement three functions:\n","\n","1. `__init__`: Initialize the dataset.\n","2. `__len__`: Returns the number of samples in the dataset.\n","3. `__getitem__`: Given a specific index, load the corresponding images and labels and return them. Necessary transformations are commonly applied here, too.\n","\n","We have implemented a dataset class for our task.\n","We have also implemented some basic transformations - you might want to add more augmentation strategies later.\n","Please take a close look at the file `dataset.py` to see how it's done."],"metadata":{"id":"22_JIoocsVB1"}},{"cell_type":"code","source":["from dataset import ImageDataset\n","from transforms import get_transforms_train, get_transforms_val\n","\n","# DataLoader for training data (Transforms include preprocessing + augmentation)\n","dataset_train = ImageDataset(data_path/'train.csv', data_path/'train.hdf5', get_transforms_train())\n","\n","# DataLoader for validation data (Transforms include only preprocessing)\n","dataset_valid = ImageDataset(data_path/'val.csv', data_path/'val.hdf5', get_transforms_val())"],"metadata":{"id":"SqME-4u-Psgk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the PyTorch Dataset only deals with loading a single image at a time.\n","The data sampling logic for loading multiple images is handled by the PyTorch DataLoader, which takes the Dataset as input and defines the logic for how to iterate over the entire dataset. To create the DataLoader, you need to use `torch.utils.data.DataLoader`, which has the following arguments:\n","\n","- `dataset`: A PyTorch Dataset.\n","- `batch_size`: Number of images to load at a time.\n","- `shuffle`: Whether to shuffle the dataset before loading the images. Usually, you will use shuffling during training and not during testing.\n","- `num_workers`: Number of subprocesses to use for data loading.\n","- ... and many more. You can find the full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n","\n","\n","We now create DataLoaders for our training and validation datasets."],"metadata":{"id":"EtOl6ftB1akd"}},{"cell_type":"code","source":["batch_size = 8\n","num_workers = 2\n","\n","# Generate our data loaders\n","train_loader = DataLoader(dataset_train, batch_size, shuffle=True, num_workers=num_workers)\n","valid_loader = DataLoader(dataset_valid, batch_size, shuffle=True, num_workers=num_workers)"],"metadata":{"id":"muUiC9Qk5bWX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize a few training samples along with the ground truth labels to get an idea of how the images look. You can run this multiple times to check different images"],"metadata":{"id":"NG4VxnMV559_"}},{"cell_type":"code","source":["# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","show_images(images[:6], labels[:6])"],"metadata":{"id":"WXMOlFmQUV8X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Define the Network\n","\n","After we've set up the data, we now need to define the network we will use to perform image classification.\n","\n","To do so, we need to create a PyTorch network.\n","To define your own PyTorch network, you need to subclass the `torch.nn.Module` class and implement two functions:\n","\n","1. `__init__`: Initialize the network, defining all the layers in the network to use.\n","2. `forward`: Defines the forward pass of the network, which takes an image as input and outputs classification scores for each class.\n","\n","As you will notice, we only have to define the forward pass of the network but not the backward pass (backpropagation). This is because PyTorch handles computing gradients for each operation for you ([autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)), so you don't have to worry about it at all!\n","\n","We've implemented a very simple CNN for you already in `cnn_network.py` with a single convolutional layer, pooling layer, and fully-connected layer. You can run this cell to see the network architecture as well as test the forward pass of the network.\n","\n","**Important:** Don't forget to import the `cnn_network.py` file every time you modify it, otherwise your latest changes won't be loaded."],"metadata":{"id":"Q_eos_y_yZF1"}},{"cell_type":"code","source":["from cnn_network import CNN\n","\n","cnn_network = CNN()  # create CNN model\n","\n","print(\"CNN Architecture:\")\n","print(cnn_network)\n","\n","print(\"\")\n","print(\"Testing network input / output.\")\n","test_input = torch.zeros(1, 3, 50, 50)  # batch size X 3 (RGB) X width X height\n","print(f\"Input shape: {test_input.shape}\")\n","test_output = cnn_network(test_input)  # batch size X # classes\n","print(f\"Output shape: {test_output.shape}\")\n","\n","assert tuple(test_output.shape) == (1, 6), \"Output shape should be [1, 6]\""],"metadata":{"id":"-JDweSSlEsYd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Define the cost function and the optimizer\n","\n","Next we define the cost function and the optimizer to be used for training.\n","\n","For the image classification task, the most commonly used loss function is the Cross-Entropy loss, which we will use here. However, feel free to play around with other losses you can think of.\n","\n","We will use the Stochastic-Gradient descent optimizer. The optimizer contains two hyperparameters, namely the learning rate and the momentum. You are free to test other optimizers. Note that PyTorch gives implementations of commonly used optimizers such as SGD, Adam, etc.\n","\n","Please check the `cnn_network.py` file to see how these components are defined."],"metadata":{"id":"Z3mubuRz6w3v"}},{"cell_type":"code","source":["from cnn_network import get_loss_function, get_optimizer\n","\n","criterion = get_loss_function()  # get loss function\n","optimizer = get_optimizer(cnn_network, lr=0.001, momentum=0.9)  # get optimizer"],"metadata":{"id":"bivhltap68Iw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Train the Network\n","\n","Now that we've defined both the data and the network, it's time to train our network on the data.\n","\n","To do so, we simply just iterate over each batch of data, compute the network loss, then optimize the network parameters with backpropagation. See the code below for details on the right way to do this in PyTorch.\n","\n","Run this cell to train the network.\n","This may take some time.\n","You should see the training loss go down in the initial iterations then plateau.\n","\n","**Note:** We reinitialize the network, and load dataset, optimizer, loss function etc again here so that it is convenient to modify them in a single place."],"metadata":{"id":"mHgFnZ2bEtxx"}},{"cell_type":"code","source":["from dataset import ImageDataset\n","from transforms import get_transforms_val, get_transforms_train\n","from cnn_network import CNN, get_loss_function, get_optimizer\n","\n","# *********************************************************** #\n","# set all training parameters. You can play around with these\n","# *********************************************************** #\n","\n","batch_size = 8           # Number of images in each batch\n","learning_rate = 0.001    # Learning rate in the optimizer\n","momentum = 0.9           # Momentum in SGD\n","num_epochs = 2           # Number of passes over the entire dataset\n","print_every_iters = 100  # Print training loss every X mini-batches\n","\n","\n","# *********************************************************** #\n","# Initialize all the training components, e.g. model, cost function\n","# *********************************************************** #\n","\n","# Get transforms\n","transform_train = get_transforms_train()\n","transform_val = get_transforms_val()\n","\n","# Generate our data loaders\n","dataset_train = ImageDataset(data_path/'train.csv', data_path/'train.hdf5', get_transforms_train())\n","dataset_valid = ImageDataset(data_path/'val.csv', data_path/'val.hdf5', get_transforms_val())\n","\n","train_loader = DataLoader(dataset_train, batch_size, shuffle=True, num_workers=2)\n","valid_loader = DataLoader(dataset_valid, batch_size, shuffle=True, num_workers=2)\n","\n","# create CNN model\n","cnn_network = CNN()\n","\n","# Get optimizer and loss functions\n","criterion = get_loss_function()\n","optimizer = get_optimizer(cnn_network, lr=learning_rate, momentum=momentum)\n","\n","\n","\n","# *********************************************************** #\n","# The main training loop. You dont need to change this\n","# *********************************************************** #\n","training_loss_per_epoch = []\n","val_loss_per_epoch = []\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","    # First we loop over training dataset\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()  # zero the gradients from previous iteration\n","\n","        # forward + backward + optimize\n","        outputs = cnn_network(inputs)  # forward pass to obtain network outputs\n","        loss = criterion(outputs, labels)  # compute loss with respect to labels\n","        loss.backward()  # compute gradients with backpropagation (autograd)\n","        optimizer.step()  # optimize network parameters\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if (i + 1) % print_every_iters == 0:\n","            print(\n","                f'[Epoch: {epoch + 1} / {num_epochs},'\n","                f' Iter: {i + 1:5d} / {len(train_loader)}]'\n","                f' Training loss: {running_loss / (i + 1):.3f}'\n","            )\n","\n","    mean_loss = running_loss / len(train_loader)\n","    training_loss_per_epoch.append(mean_loss)\n","\n","    # Next we loop over validation dataset\n","    running_loss = 0.0\n","    for i, data in enumerate(valid_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # on validation dataset, we only do forward, without computing gradients\n","        with torch.no_grad():\n","            outputs = cnn_network(inputs)  # forward pass to obtain network outputs\n","            loss = criterion(outputs, labels)  # compute loss with respect to labels\n","\n","        # print statistics\n","        running_loss += loss.item()\n","\n","    mean_loss = running_loss / len(valid_loader)\n","    val_loss_per_epoch.append(mean_loss)\n","\n","    print(\n","        f'[Epoch: {epoch + 1} / {num_epochs}]'\n","        f' Validation loss: {mean_loss:.3f}'\n","    )\n","\n","print('Finished Training')\n","\n","# Plot the training curves\n","plt.figure()\n","plt.plot(np.array(training_loss_per_epoch))\n","plt.plot(np.array(val_loss_per_epoch))\n","plt.legend(['Training loss', 'Val loss'])\n","plt.xlabel('Epoch')\n","plt.show()\n","plt.close()"],"metadata":{"id":"CEwO7VTRVBvd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Test the Network\n","\n","After training the network, it is time to test our network on the validation set, which includes images not seen during training. This will tell us how well the network can perform on new data.\n","\n","We first visualize several network predictions on validation samples along with the ground truth labels.\n","You can run this cell multiple times to visualize different images."],"metadata":{"id":"pPK21YPU4Dlu"}},{"cell_type":"code","source":["# get a few validation samples\n","images, labels = next(iter(valid_loader))\n","\n","# get network output\n","outputs = cnn_network(images)  # classification scores\n","_, predicted = torch.max(outputs, 1)  # use maximum as prediction label\n","\n","# visualize ground truth and predictions\n","show_images(images[:4], labels[:4], predicted[:4])"],"metadata":{"id":"i5jh68veoG0g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To get the full picture of the network performance, we need to evaluate on the full validation set.\n","This cell will iterate over every validation image, obtain the network prediction, and compare with the corresponding ground truth.\n","The evaluation score is the percentage of labels predicted correctly.\n","This may take some time.\n","You should see an accuracy of around 63%."],"metadata":{"id":"CgDjbsNGzdBt"}},{"cell_type":"code","source":["from utils import compute_accuracy\n","\n","acc = compute_accuracy(cnn_network, valid_loader)\n","print(f'Accuracy of the network on the 1500 validation images: {acc:.2f} %')"],"metadata":{"id":"Dww7gr6DorWm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Your Turn\n","\n","**TODO:** We provided a simple CNN and boilerplate training code to introduce PyTorch to you.\n","These are written in their simplest form to leave ample room for extension.\n","Your task is to improve the network's performance on the test set.\n","\n","**Note:** You are not allowed to use any external packages except the ones already imported in `cnn_network.py`. Otherwise your submission will crash on the Evaluation server.\n","\n","\n","**Hints:** Things that can potentially improve test accuracy:\n","- Deeper architecture: Adding more layers can lead to better performance, but be careful of overfitting to the training set!\n","- Activation functions: Introducing activation functions can increase the capacity of the network.\n","- Training parameters: Modifying the length of training, learning rate, optimizer, loss function, etc. can all improve network performance, but again be careful of overfitting!\n","- Transforms: Adding data transforms essentially generates more data for training, which helps alleviate overfitting. See full list of available transforms [here](https://pytorch.org/vision/stable/transforms.html)."],"metadata":{"id":"tuYmX9DRxRUT"}},{"cell_type":"markdown","source":["## Generate the final submission on the test set\n","\n","When you are happy with your network, you can run the next cell to generate your submission.\n","We will copy the relevant files, as well as save the learned model parameters to the submission folder.\n","As usual, download the submission folder (**without renaming**) as a zip, and upload it to the evaluation server. There your code will run to predict the test image labels."],"metadata":{"id":"7r0OT0aVvkWi"}},{"cell_type":"code","source":["out_dir = env_path / 'submission'\n","out_dir.mkdir(exist_ok=True)\n","\n","cnn_network.write_weights(out_dir / 'checkpoint.pt')\n","shutil.copyfile(env_path / 'cnn_network.py', out_dir / 'cnn_network.py')\n","shutil.copyfile(env_path / 'transforms.py', out_dir / 'transforms.py')\n","\n","print(\"Done. You can submit now.\")"],"metadata":{"id":"VQUz2RxN1pUS"},"execution_count":null,"outputs":[]}]}