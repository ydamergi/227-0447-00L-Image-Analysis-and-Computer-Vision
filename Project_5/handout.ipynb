{"cells":[{"cell_type":"markdown","metadata":{"id":"5DYJwNdGOrc-"},"source":["# IACV Exercise 5: Transfer Learning\n","\n","In this exercise, you will again tackle the image classification task, as in exercise 4.\n","Given an input RGB image with resolution `(32, 32, 3)`, you need to predict which of the 10 input classes it belongs to.\n","However, unlike in exercise 4, you have access to limited training data in `training.h5`.\n","In fact, you only have `210` samples per class, which are separated into training, validation, and test sets of ratio `7:1:2` for ease of use.\n","You can use these three sets of data for your development.\n","\n","Fortunately, you have access to a pre-trained network which has been trained on large amounts of data to classify 5 out of 10 input classes.\n","That is, the pre-trained network obtains a classification accuracy of around 95% for 5 of the classes, while the remaining classes are not defined at all.\n","The pretrained parameters are stored in `ckpt/resnet4five.pt` and the loading process explained below.\n","\n","Your task is to either adapt this model, or train a new network from scratch which can classify all 10 classes.\n","Similar to exercise 4, we will use the [PyTorch](https://https://pytorch.org/) deep learning framework in this exercise.\n","\n","**Evaluation Criteria**\n","\n","Your algorithm will be evaluated using classification accuracy, which is the proportion of images with the correct predicted label.\n","The final EvaluationScore is obtained as the classification accuracy over all test samples, over all 10 classes.\n","The real test data used for evaluation has 1000 images without labels and can be found in `test.h5`\n","\n","**Rules**\n","\n","Throughout this project, you are **not allowed to use any other dataset and/or pre-trained model other than the given ones**.\n","You are allowed to use any other techniques you have learned in the course, including but not limited to\n","*data augmentation, early stopping, and transfer learning*."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19088,"status":"ok","timestamp":1702569749983,"user":{"displayName":"Georg Brunner","userId":"13715173491527462388"},"user_tz":-60},"id":"PwCTa9CLPHYb","outputId":"01211d88-4de6-4a65-9070-0e765532bcaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# These two lines ensure that we always import the latest version of a package\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","\n","import os\n","import sys\n","import shutil\n","from pathlib import Path\n","\n","import torch\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"w157_tWbPUhU","executionInfo":{"status":"ok","timestamp":1702569751745,"user_tz":-60,"elapsed":204,"user":{"displayName":"Georg Brunner","userId":"13715173491527462388"}}},"outputs":[],"source":["iacv_path = 'MyDrive/BMIC/iacv/hs23_ex_wip/ex5/handout' # TODO set this\n","\n","env_path = Path('/content/drive/') / iacv_path\n","# Add the handout folder to python paths\n","if env_path not in sys.path:\n","    sys.path.append(str(env_path))"]},{"cell_type":"markdown","metadata":{"id":"AIZmtynK8aY0"},"source":["## Mapping from 5 to 10 classes\n","\n","Define a mapping from 5 to 10 classes because the indices do not match, such as `classes[0]` is `Airplane` while `classes5[0]` is `Cat`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tj7vLLTsImlM"},"outputs":[],"source":["# Mapping from 5 to 10 classes\n","\n","# Classes for the pretrained dataset\n","classes5 = [\"Cat\", \"Deer\", \"Frog\", \"Ship\", \"Truck\"]\n","\n","# Actual classes\n","classes = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n","           \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","\n","# Converting numpy arrays for indexing\n","classes5 = np.array(classes5)\n","classes = np.array(classes)\n","\n","# Mapping from 5 classes to 10 classes for evaluation\n","map5to10 = [np.where(classes==class_)[0][0] for class_ in classes5]\n","map5to10 = np.array(map5to10)\n","print(\"Mapping array is:\", map5to10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFEMjFFL-AOQ"},"outputs":[],"source":["# Example usage\n","\n","# Random predictions by 5\n","preds5 = np.random.randint(5, size=7, dtype=int)\n","\n","# Predicted classes\n","print(\"Actual Predictions:        \", classes5[preds5])\n","\n","# Wrong mapping from 5 to 10 classes\n","print(\"Wrongly-mapped Predictions:\", classes[preds5])\n","\n","# Correct mapping from 5 to 10 classes\n","print(\"Correct-mapped Predictions:\", classes[map5to10[preds5]])"]},{"cell_type":"markdown","metadata":{"id":"w2LFx6yAPZoI"},"source":["## Create dataloaders\n","\n","We have implemented the basic data handling.\n","You might want to check out the file `dataset.py` nonetheless.\n","In case you want to apply data augmentations during training, etc...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z4r22MAOrdC"},"outputs":[],"source":["from dataset import get_datasets_from_h5, get_loaders_from_datasets\n","\n","# Get the datasets\n","data_path = env_path / 'data'\n","train_dataset, val_dataset, test_dataset = get_datasets_from_h5(data_path / 'training.h5')\n","\n","# Construct the dataloaders\n","batch_size = 24\n","train_loader, val_loader, test_loader = \\\n","    get_loaders_from_datasets(train_dataset, val_dataset, test_dataset,\n","                              batch_size)\n","\n","# Create the model and summarize\n","num_classes = train_dataset.num_classes\n","input_size = train_dataset.image_size\n","\n","# Print the sizes of the datasets\n","print(f\"The dataset contains {train_dataset.num_classes} classes.\")\n","print(f\"Number of images in each dataset: Training={len(train_dataset)}, \",\n","      f\"Validation={len(val_dataset)}, Test={len(test_dataset)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"23Ihu991RwDg"},"source":["## Visualize training images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1PrWX3TSAWe"},"outputs":[],"source":["from utils import show_images\n","\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","show_images(images[:6], classes[labels[:6]])"]},{"cell_type":"markdown","metadata":{"id":"cukc9chqOrdD"},"source":["## Load pre-trained model\n","\n","As mentioned before, you have access to parameters of a pre-trained model `resnet4five.pt`, which is a standard ResNet18 model and has been trained to classify images into 5 classes (\"Cat\", \"Deer\", \"Frog\", \"Ship\", \"Truck\"), using larger dataset. It achieves accuracy of higher than 90% for these classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sm2uH5G0Tk3q"},"outputs":[],"source":["from model import generate_resnet\n","\n","# Path to load the model from\n","load_path = env_path / 'ckpt' / 'resnet4five.pt'\n","\n","# Device to train on\n","device = torch.device(\"cpu\")\n","\n","# Create the model with 5 output classes\n","model = generate_resnet(num_classes=5)\n","\n","# Next we load the pre-trained weights, and set it to the model we created\n","model.load_state_dict(torch.load(load_path, map_location=device))"]},{"cell_type":"markdown","metadata":{"id":"7n8VFaxYUa2T"},"source":["Next, we can test the pre-trained model on the dataset.\n","Check out the file `evaluation.py` to see how the model is used to make a prediction.\n","A very similar code will be used to create your prediction at the end of this file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1zWLG_0OrdE"},"outputs":[],"source":["from evaluation import evaluate_model\n","from utils import show_class_accs\n","\n","# Evaluate the model\n","test_accuracy = evaluate_model(model, test_loader, device=device,\n","                               mapping=map5to10)\n","print(f\"Test accuracy with pretrained model: {test_accuracy:.3f}\")\n","\n","# Classwise accuracies\n","test_class_accs = evaluate_model(model, test_loader, device=device,\n","                               mapping=map5to10, classwise=True)\n","\n","show_class_accs(test_class_accs, classes, title=\"Test\")"]},{"cell_type":"markdown","metadata":{"id":"xz4VjaxmWse6"},"source":["As expected, we see the the pre-trained model obtains good performance on the 5 out of 10 classes which it has been trained for. However, it cannot handle the other 5 *unseen* classes, and thus obtains a low overall classification accuracy. Your task is to adapt this pre-trained model such that it obtains better overall classification accuracy, i.e. > 60%."]},{"cell_type":"markdown","metadata":{"id":"9bThsKaQEDzh"},"source":["## Your Solution\n","\n","You can write your own implementation here.\n","You can change the custom functions given according to your needs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOLPuce0A5gj"},"outputs":[],"source":["# For convenience reimport all custom functions\n","from utils import seed_everything\n","from model import generate_resnet\n","from dataset import get_datasets_from_h5, get_loaders_from_datasets\n","from training import train_model, plot_training_log\n","from evaluation import evaluate_model\n","\n","from torchsummary import summary\n","\n"," # Give your Legi number as random seed\n","seed = 15941073\n","seed_everything(seed)\n","\n","#\n","# Write your implementation here\n","# You can also implement the training loop in the file `training.py`\n","#"]},{"cell_type":"markdown","metadata":{"id":"1LI94WFCbRtQ"},"source":["## Generating the final submission\n","\n","When you are happy with your network, you can run the next cell to generate your network predictions on the test set, which will be stored in the submission directory on your Google Drive.\n","Download the submission folder (without renaming) as a zip, and upload it to the evaluation server to obtain the scores on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5cu-b_AB8Rp"},"outputs":[],"source":["from dataset import get_test_loader\n","\n","test_h5_path = env_path / 'data' / 'test.h5'\n","\n","submission_path = env_path / 'submission'\n","submission_path.mkdir(exist_ok=True)\n","\n","# Choose device to run inference\n","device = torch.device(\"cuda\")\n","\n","# Load test dataset and dataloader\n","test_loader = get_test_loader(test_h5_path)\n","\n","# Predictions to store\n","predictions = list()\n","\n","# Set to evaluation mode\n","model.eval()\n","\n","# Iterate over the test set\n","with torch.no_grad():\n","    for images, _ in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        # Get the predictions\n","        _, preds = torch.max(outputs, 1)\n","        preds = preds.cpu()\n","        predictions.extend(preds.tolist())\n","\n","# Save the outputs (do not change the name)\n","np.savetxt(submission_path / 'labels.csv', predictions, fmt=\"%d\")\n","\n","# Save the relevant files (do not change the name)\n","shutil.copyfile(env_path / 'model.py', submission_path / 'model.py')\n","shutil.copyfile(env_path / 'dataset.py', submission_path / 'dataset.py')\n","shutil.copyfile(env_path / 'training.py', submission_path / 'training.py')\n","shutil.copyfile(env_path / 'handout.ipynb', submission_path / 'handout.ipynb')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"b8ecf7fafc54fa33b4025afd9bff0a8d28b549f5b10ab097d7a2df0f41da54c9"}}},"nbformat":4,"nbformat_minor":0}